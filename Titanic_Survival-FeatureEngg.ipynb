{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://FireBall:4041\n",
       "SparkContext available as 'sc' (version = 2.4.0, master = local[*], app id = local-1552503973906)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.Pipeline\r\n",
       "import org.apache.spark.ml.classification.LogisticRegression\r\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\r\n",
       "import org.apache.spark.ml.feature.{VectorAssembler, IndexToString, StringIndexer, VectorIndexer}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Import the required dependencies\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{VectorAssembler, IndexToString, StringIndexer, VectorIndexer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "titanic_dataset: org.apache.spark.sql.DataFrame = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val titanic_dataset = spark.read.\n",
    "                  option(\"header\",\"true\").\n",
    "                  option(\"inferSchema\",\"true\").\n",
    "                  option(\"mode\", \"DROPMALFORMED\").\n",
    "                  csv(\"file:///C:/Users/FireBall/Downloads/SCALA_SPARK/Dataset/Titanic dataset/train.csv\")\n",
    "                  //.na.drop()    don't perform it just after reading the dataset. \n",
    "                  //Preprocess and then when we are fitting the model on dataset, we should drop NA/NULL fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dataset.createOrReplaceTempView(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Embarked|\n",
      "+--------+\n",
      "|    null|\n",
      "|       C|\n",
      "|       Q|\n",
      "|       S|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select distinct Embarked from titanic order by Embarked\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colNames: Array[String] = Array(PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked)\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val colNames = titanic_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[org.apache.spark.sql.Row] = Array([1,0,3,Braund, Mr. Owen Harris,male,22.0,1,0,A/5 21171,7.25,null,S])\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[org.apache.spark.sql.Row] = Array()\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_dataset.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "firstRow: org.apache.spark.sql.Row = [1,0,3,Braund, Mr. Owen Harris,male,22.0,1,0,A/5 21171,7.25,null,S]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val firstRow = titanic_dataset.head(1)(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "First Row Data\n",
      "Survived :\t0\n",
      "Pclass :\t3\n",
      "Name :\tBraund, Mr. Owen Harris\n",
      "Sex :\tmale\n",
      "Age :\t22.0\n",
      "SibSp :\t1\n",
      "Parch :\t0\n",
      "Ticket :\tA/5 21171\n",
      "Fare :\t7.25\n",
      "Cabin :\tnull\n",
      "Embarked :\tS\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n\")\n",
    "println(\"First Row Data\")\n",
    "for ( i <- 1 until colNames.length){\n",
    "    println(colNames(i) + \" :\\t\" +firstRow(i))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LORdata_all: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 6 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LORdata_all = titanic_dataset.select(titanic_dataset(\"Survived\").as(\"label\"), \n",
    "                                         $\"Pclass\",$\"Sex\",$\"Age\",$\"SibSp\",$\"Parch\",$\"Fare\",$\"Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOR_data: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 6 more fields]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LOR_data = LORdata_all.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.linalg.Vectors\r\n",
       "import org.apache.spark.ml.feature.OneHotEncoderEstimator\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.ml.feature.OneHotEncoderEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genderIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_e0ff14faad24\r\n",
       "embarkIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_1e784b20d52d\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Converting Strings into numerical values\n",
    "val genderIndexer = new StringIndexer()\n",
    "                        .setInputCol(\"Sex\")\n",
    "                        .setOutputCol(\"SexIndexer\")\n",
    "val embarkIndexer = new StringIndexer()\n",
    "                        .setInputCol(\"Embarked\")\n",
    "                        .setOutputCol(\"EmbarkedIndexer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genderEncoder: org.apache.spark.ml.feature.OneHotEncoderEstimator = oneHotEncoder_a2edcb67cb1c\r\n",
       "embarkEncoder: org.apache.spark.ml.feature.OneHotEncoderEstimator = oneHotEncoder_2038cd46d496\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Convert Numerical values to One HotEncoder 0 or 1\n",
    "val genderEncoder = new OneHotEncoderEstimator()\n",
    "                        .setInputCols(Array(\"SexIndexer\"))\n",
    "                        .setOutputCols(Array(\"SexVec\"))\n",
    "val embarkEncoder = new OneHotEncoderEstimator()\n",
    "                        .setInputCols(Array(\"EmbarkedIndexer\"))\n",
    "                        .setOutputCols(Array(\"EmbarkedVec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembeler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_f981d49bc03c\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Label & Features\n",
    "val assembeler = new VectorAssembler().setInputCols(Array(\"Pclass\", \"SexVec\", \"Age\", \"SibSp\", \n",
    "                                                          \"Parch\", \"Fare\", \"EmbarkedVec\"))\n",
    "                                      .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LORalgo: org.apache.spark.ml.classification.LogisticRegression = logreg_14fe6cb75229\r\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_103b4251f93b\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LORalgo = new LogisticRegression()\n",
    "                 //.setMaxIter(10)\n",
    "                 //.setRegParam(0)\n",
    "                 //.setElasticNetParam(0)\n",
    "\n",
    "val pipeline = new Pipeline().setStages(Array(genderIndexer,embarkIndexer,genderEncoder,embarkEncoder,assembeler,LORalgo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-14 00:37:22 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2019-03-14 00:37:22 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.PipelineModel = pipeline_103b4251f93b\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(LOR_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_dataset: org.apache.spark.sql.DataFrame = [PassengerId: int, Pclass: int ... 9 more fields]\r\n",
       "Survived_dataset: org.apache.spark.sql.DataFrame = [PassengerId: int, Survived: int]\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test_dataset = spark.read.\n",
    "                  option(\"header\",\"true\").\n",
    "                  option(\"inferSchema\",\"true\").\n",
    "                  option(\"mode\", \"DROPMALFORMED\").\n",
    "                  csv(\"file:///C:/Users/FireBall/Downloads/SCALA_SPARK/Dataset/Titanic dataset/test.csv\")\n",
    "                  //.na.drop()\n",
    "val Survived_dataset = spark.read.\n",
    "                  option(\"header\",\"true\").\n",
    "                  option(\"inferSchema\",\"true\").\n",
    "                  option(\"mode\", \"DROPMALFORMED\").\n",
    "                  csv(\"file:///C:/Users/FireBall/Downloads/SCALA_SPARK/Dataset/Titanic dataset/gender_submission.csv\")\n",
    "                  //.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+-----------+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|PassengerId|Survived|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+-----------+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0| 330911| 7.8292| null|       Q|        892|       0|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0| 363272|    7.0| null|       S|        893|       1|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0| 240276| 9.6875| null|       Q|        894|       0|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0| 315154| 8.6625| null|       S|        895|       0|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|3101298|12.2875| null|       S|        896|       1|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset.join(Survived_dataset, test_dataset(\"PassengerId\") === Survived_dataset(\"PassengerId\"),\"inner\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|Survived|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0| 330911| 7.8292| null|       Q|       0|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0| 363272|    7.0| null|       S|       1|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0| 240276| 9.6875| null|       Q|       0|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0| 315154| 8.6625| null|       S|       0|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|3101298|12.2875| null|       S|       1|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "joined_df: org.apache.spark.sql.DataFrame = [PassengerId: int, Pclass: int ... 10 more fields]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.createOrReplaceTempView(\"test_table\")\n",
    "Survived_dataset.createOrReplaceTempView(\"Survived_table\")\n",
    "\n",
    "val joined_df = spark.sql( \"select t.*,s.Survived \n",
    "                            from test_table t \n",
    "                            inner join Survived_table s \n",
    "                            on s.PassengerId = t.PassengerId\")\n",
    "joined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----------------+----+----+-----+-----+------+------+-----+--------+--------+\n",
      "|PassengerId|Pclass|            Name| Sex| Age|SibSp|Parch|Ticket|  Fare|Cabin|Embarked|Survived|\n",
      "+-----------+------+----------------+----+----+-----+-----+------+------+-----+--------+--------+\n",
      "|        892|     3|Kelly, Mr. James|male|34.5|    0|    0|330911|7.8292| null|       Q|       0|\n",
      "+-----------+------+----------------+----+----+-----+-----+------+------+-----+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.createOrReplaceTempView(\"Joined_testdata\")\n",
    "spark.sql(\"select * from Joined_testdata where PassengerId = 892 \").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOR_Testdata_all: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 6 more fields]\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LOR_Testdata_all = joined_df.select(joined_df(\"Survived\").as(\"label\"), \n",
    "                                         $\"Pclass\",$\"Sex\",$\"Age\",$\"SibSp\",$\"Parch\",$\"Fare\",$\"Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOR_Testdata: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 6 more fields]\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LOR_Testdata = LOR_Testdata_all.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+----+-----+-----+-------+--------+\n",
      "|label|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+-----+------+------+----+-----+-----+-------+--------+\n",
      "|    0|     3|  male|34.5|    0|    0| 7.8292|       Q|\n",
      "|    1|     3|female|47.0|    1|    0|    7.0|       S|\n",
      "|    0|     2|  male|62.0|    0|    0| 9.6875|       Q|\n",
      "|    0|     3|  male|27.0|    0|    0| 8.6625|       S|\n",
      "|    1|     3|female|22.0|    1|    1|12.2875|       S|\n",
      "+-----+------+------+----+-----+-----+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOR_Testdata.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results: org.apache.spark.sql.DataFrame = [label: int, Pclass: int ... 14 more fields]\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = model.transform(LOR_Testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+----+-----+-----+------+--------+----------+---------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|Pclass|   Sex| Age|SibSp|Parch|  Fare|Embarked|SexIndexer|EmbarkedIndexer|       SexVec|  EmbarkedVec|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+------+------+----+-----+-----+------+--------+----------+---------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|     3|  male|34.5|    0|    0|7.8292|       Q|       0.0|            2.0|(1,[0],[1.0])|    (2,[],[])|(8,[0,1,2,5],[3.0...|[0.38677297509601...|[0.59550561797752...|       0.0|\n",
      "|    1|     3|female|47.0|    1|    0|   7.0|       S|       1.0|            0.0|    (1,[],[])|(2,[0],[1.0])|[3.0,0.0,47.0,1.0...|[0.38677297509601...|[0.59550561797752...|       0.0|\n",
      "+-----+------+------+----+-----+-----+------+--------+----------+---------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_41dc39073ea6\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy: Double = 0.6163141993957704\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val accuracy = evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precisionevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_0087f50dfa29\r\n",
       "precision: Double = 0.3798431923768494\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Precisionevaluator = new MulticlassClassificationEvaluator()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"weightedPrecision\")\n",
    "val precision = Precisionevaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recallevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_92c10ae8516f\r\n",
       "Recall: Double = 0.3798431923768494\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Recallevaluator = new MulticlassClassificationEvaluator()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"weightedPrecision\")\n",
    "val Recall = Recallevaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F1scoreevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_65dafa756a04\r\n",
       "F1Score: Double = 0.47001157636163415\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val F1scoreevaluator = new MulticlassClassificationEvaluator()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"f1\")\n",
    "val F1Score = F1scoreevaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\r\n",
       "AreaROCEvaluator: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_c82e4a81ed8f\r\n",
       "AreaROC: Double = 0.5\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "val AreaROCEvaluator = new BinaryClassificationEvaluator()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setRawPredictionCol(\"rawPrediction\")\n",
    "  .setMetricName(\"areaUnderROC\")\n",
    "val AreaROC = AreaROCEvaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
